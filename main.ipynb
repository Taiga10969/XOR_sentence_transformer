{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#必要ライブラリのインポート\n",
    "#pip install --upgrade jupyter ipywidgets\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルの定義\n",
    "model = SentenceTransformer('all-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用データの選択\n",
    "dataset_path = '/taiga/Datasets/scicap_plus'\n",
    "\n",
    "cap_path = 'captions/test/1001.0196v1-Figure2-1.json' #captionデータ1\n",
    "men_paths = [\n",
    "    'mentions_paragraph/test/1001.0196v1-Figure2-1_mentions.npy', #mentionデータ1\n",
    "    'mentions_paragraph/test/1001.1020v1-Figure1-1_mentions.npy', #mentionデータ2\n",
    "    'mentions_paragraph/test/1001.3663v1-Figure4-1_mentions.npy', #mentionデータ3\n",
    "    'mentions_paragraph/test/1001.3689v1-Figure5-1_mentions.npy', #mentionデータ4\n",
    "    'mentions_paragraph/test/1001.4519v1-Figure6-1_mentions.npy', #mentionデータ5\n",
    "]\n",
    "\n",
    "\n",
    "datas = []\n",
    "\n",
    "#capデータ\n",
    "with open(os.path.join(dataset_path, cap_path), 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "    datas.append(data['2-normalized']['2-1-basic-num']['caption']) #captionデータは'2-normalized'されたデータを使用\n",
    "\n",
    "#menデータ\n",
    "for men_path in men_paths:\n",
    "    data = np.load(os.path.join(dataset_path, men_path), allow_pickle=True).item()\n",
    "    datas.append(data['mentions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_sentences :  (384,)\n"
     ]
    }
   ],
   "source": [
    "#sentence_embedingの実行\n",
    "embed_datas = []\n",
    "\n",
    "for data in datas:\n",
    "    embed_sentence = model.encode(data)\n",
    "    embed_datas.append(embed_sentence)\n",
    "\n",
    "print(\"embed_sentences : \", np.shape(embed_sentence)) #埋め込みベクトルの埋め込み次元数の確認 >> (384,) 384次元のベクトルが生成されていることを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption :  write performance of the wan file systems .\n",
      "--------------------------------------------------\n",
      "cap1, men1 : tensor([0.5802])\n",
      "mention :  operation in all our measurements to include the cost of cache flushes. The throughput for the write and read performance is shown in Figure 2 and Figure 3.\n",
      "--------------------------------------------------\n",
      "cap1, men2 : tensor([0.1575])\n",
      "mention :  Figure 1 provides the comparisons on the six (correlated) noise datasets: M-Noise1 to M-Noise6. Table 4 compares the error rates on M-Basic, M-Rotate, M-Image, M-Rand, and M-RotImg.\n",
      "--------------------------------------------------\n",
      "cap1, men3 : tensor([0.1917])\n",
      "mention :  This section shows the comparison of the topological measurements across the three level collaboration networks. Figure 4 depicts the network sizes at the three level collaboration networks over the eight years. Because the author level collaboration networks have a large number of nodes and edges than corresponding networks at the other two aggregated levels, we use logarithmic scale in the y axis. Figure 4 shows that the number of nodes at all three level collaboration networks\n",
      "--------------------------------------------------\n",
      "cap1, men4 : tensor([0.4603])\n",
      "mention :  We perform the simulation for different values of N, the number of sources from which a carrier keeps packets in its buffer (N = 1 is equivalent to flushing the buffer upon reaching every new source). Figure 5 compares the MDD for both schemes. As Figure 5(b) suggests, for high values of N, scheme B outperforms scheme A. This result conforms the intuitive solution presented in (11). Because, for large values of N, the carrier node keeps packets form previous sources for a longer amount of time and in fact shares the available buffer space on the road between all sources in a window of size N. When N is large, packets from far source stay longer at the carrier buffer and hence giving more chance to the collectors to gather packets from the far source. It is worth noting that large N results in relative fairness between sources.\n",
      "--------------------------------------------------\n",
      "cap1, men5 : tensor([0.3220])\n",
      "mention :  Figs. 6 and 7 quantify the average and outage probabilities for several scenarios, showing their dependence on various parameters involved, such as the signal-to-noise ratio SNR = E0/N0, interference-to-noise ratio INR = E/N0, amplitude loss exponent b, interferer spatial density λ, and link length r0.\n"
     ]
    }
   ],
   "source": [
    "# data[0] (cap1) とdat[1:] (men1-5) の埋め込み表現のコサイン類似度を算出\n",
    "\n",
    "similarity_scores = []\n",
    "print(\"caption : \", datas[0])\n",
    "for index, embed_data in enumerate(embed_datas[1:]):\n",
    "     similarity_score = cosine_similarity(torch.unsqueeze(torch.tensor(embed_datas[0]), dim=0), torch.unsqueeze(torch.tensor(embed_data), dim=0))\n",
    "     similarity_scores.append(similarity_score)\n",
    "     print('-'*50)\n",
    "     print(f\"cap1, men{index+1} : {similarity_score}\")\n",
    "     print(\"mention : \", datas[index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_num_words(text, num=10):\n",
    "    # 文字列を空白で分割して単語のリストを作成\n",
    "    words = text.split()\n",
    "    # 最初の10単語を取得し、空白で連結して文字列にする\n",
    "    first_num_words = ' '.join(words[:num])\n",
    "    return first_num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_sentences :  (384,)\n",
      "caption :  write performance of the wan file systems .\n",
      "--------------------------------------------------\n",
      "cap1, men1 : tensor([0.5995])\n",
      "mention :  operation in all our measurements to include the cost of cache flushes. The throughput for the write and read performance is shown in Figure 2 and Figure 3.\n",
      "--------------------------------------------------\n",
      "cap1, men2 : tensor([0.1617])\n",
      "mention :  Figure 1 provides the comparisons on the six (correlated) noise datasets: M-Noise1 to M-Noise6. Table 4 compares the error rates on M-Basic, M-Rotate, M-Image, M-Rand, and M-RotImg.\n",
      "--------------------------------------------------\n",
      "cap1, men3 : tensor([0.2110])\n",
      "mention :  This section shows the comparison of the topological measurements across the three level collaboration networks. Figure 4 depicts the network sizes at the three level collaboration networks over the eight years. Because the author level collaboration networks have a large number of nodes and edges than corresponding networks at the other two aggregated levels, we use logarithmic scale in the y axis. Figure 4 shows that the number of nodes at all three level collaboration networks\n",
      "--------------------------------------------------\n",
      "cap1, men4 : tensor([0.3009])\n",
      "mention :  We perform the simulation for different values of N, the number of sources from which a carrier keeps packets in its buffer (N = 1 is equivalent to flushing the buffer upon reaching every new source). Figure 5 compares the MDD for both schemes. As Figure 5(b) suggests, for high values of N, scheme B outperforms scheme A. This result conforms the intuitive solution presented in (11). Because, for large values of N, the carrier node keeps packets form previous sources for a longer amount of time and in fact shares the available buffer space on the road between all sources in a window of size N. When N is large, packets from far source stay longer at the carrier buffer and hence giving more chance to the collectors to gather packets from the far source. It is worth noting that large N results in relative fairness between sources.\n",
      "--------------------------------------------------\n",
      "cap1, men5 : tensor([0.2615])\n",
      "mention :  Figs. 6 and 7 quantify the average and outage probabilities for several scenarios, showing their dependence on various parameters involved, such as the signal-to-noise ratio SNR = E0/N0, interference-to-noise ratio INR = E/N0, amplitude loss exponent b, interferer spatial density λ, and link length r0.\n"
     ]
    }
   ],
   "source": [
    "#文章の長さに関係があるのか調査\n",
    "#全文章を先頭から20単語分のみ抽出\n",
    "\n",
    "extracted_datas = []\n",
    "for data in datas:\n",
    "    extract_text = extract_first_num_words(text=data, num=20)\n",
    "    extracted_datas.append(extract_text)\n",
    "\n",
    "\n",
    "#sentence_embedingの実行\n",
    "embed_extracted_datas = []\n",
    "\n",
    "for extracted_data in extracted_datas:\n",
    "    embed_extracted_sentence = model.encode(extracted_data)\n",
    "    embed_extracted_datas.append(embed_extracted_sentence)\n",
    "\n",
    "print(\"embed_sentences : \", np.shape(embed_extracted_sentence)) #埋め込みベクトルの埋め込み次元数の確認 >> (384,) 384次元のベクトルが生成されていることを確認\n",
    "\n",
    "# data[0] (cap1) とdat[1:] (men1-5) の埋め込み表現のコサイン類似度を算出\n",
    "\n",
    "similarity_scores_extracted = []\n",
    "print(\"caption : \", datas[0])\n",
    "for index, embed_extracted_data in enumerate(embed_extracted_datas[1:]):\n",
    "     similarity_score_extracted = cosine_similarity(torch.unsqueeze(torch.tensor(embed_extracted_datas[0]), dim=0), torch.unsqueeze(torch.tensor(embed_extracted_data), dim=0))\n",
    "     similarity_scores_extracted.append(similarity_score_extracted)\n",
    "     print('-'*50)\n",
    "     print(f\"cap1, men{index+1} : {similarity_score_extracted}\")\n",
    "     print(\"mention : \", datas[index+1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
